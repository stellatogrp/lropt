{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning problem - portfolio optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import numpy.testing as npt\n",
    "import scipy as sc\n",
    "import torch\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from tests.settings import SOLVER\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lropt.parameter import Parameter\n",
    "from lropt.robust_problem import RobustProblem\n",
    "from lropt.uncertain import UncertainParameter\n",
    "from lropt.uncertainty_sets.ellipsoidal import Ellipsoidal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the classic portfolio management problem where we select a portfolio $x \\in \\reals^n$ of stocks to maximize returns. Our selected stock should not deviate too far from our previous holdings, denoted $x^{\\text{prev}} \\in \\reals^n$. The trading cost of the total deviations is $0.2\\|x - x^{\\text{prev}}\\|_1$.\n",
    "\n",
    "We model returns as $u$, and thus the objective to minimize is \n",
    "$$-u^Tx + 0.2\\|x - x^{\\text{prev}}\\|_1.$$\n",
    "To account for uncertainty in the returns $u$, we introduce a new variable $t$ to write the objective in epigraph form, obtaining the RO problem \n",
    "\\begin{equation*}\n",
    "\t\\begin{array}{ll}\n",
    "\t\t\\text{minimize} & t + 0.2\\|x - x^{\\text{prev}}\\|_1\\\\\n",
    "\t\t\\text{subject to} & -u^Tx \\le t \\quad \\forall u \\in \\mathcal{U}(\\theta) \\\\\n",
    "\t\t& 1^Tx = 1, \\quad x \\geq 0.\n",
    "\t\\end{array}\n",
    "\\end{equation*}\n",
    "\n",
    "We generate the uncertain demand $u$ from a Normal distribution, with parameters\n",
    "\\begin{equation*}\n",
    "\t\\mu =\n",
    "\\left[ \\begin{array}{l} 0.3 \\\\\n",
    "0.3 \\end{array} \\right],\\quad \\Sigma =\n",
    "\\left[\\begin{array}{ll} \\phantom{-}0.5 & -0.3\\\\\n",
    "-0.3 & \\phantom{-}0.4 \\end{array} \\right].\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_demand_intro(N, seed):\n",
    "    \"\"\"\n",
    "    This function generates random demand.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    sig = np.array([[0.5, -0.3], [-0.3, 0.4]])\n",
    "    mu = np.array((0.3, 0.3))\n",
    "    d_train = np.random.multivariate_normal(mu, sig, N)\n",
    "    # d_train = np.exp(d_train)\n",
    "    return d_train\n",
    "\n",
    "n = 2\n",
    "N = 100\n",
    "data = gen_demand_intro(600, seed=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parametrize the optimization problem by $y = x^{\\text{prev}}$, the previous holdings.\n",
    "We consider the parameter $y$ with finite support; in particular, we consider 10 possible values of $y$.\n",
    "To enforce holdings summing up to $1$, we set each instance of the previous holdings $x^{\\text{prev}}$ using the Dirichlet distribution, with parameter value $(2.5,1)$, corresponding to the 2 different stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15)\n",
    "dist = np.array((2.5,1.0))\n",
    "y_data = np.random.dirichlet(dist, 10)\n",
    "y = Parameter(n, data=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the robust problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = UncertainParameter(n,uncertainty_set=Ellipsoidal(p=2,data=data))\n",
    "\n",
    "x = cp.Variable(n)\n",
    "t = cp.Variable()\n",
    "\n",
    "objective = cp.Minimize(t + 0.2*cp.norm(x - y, 1))\n",
    "constraints = [-x@u <= t, cp.sum(x) == 1, x >= 0]\n",
    "eval_exp = -x @ u + 0.2*cp.norm(x-y, 1)\n",
    "prob = RobustProblem(objective, constraints, eval_exp=eval_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize the mean-variance uncertainty set, as well as the training problem. We run the algorithm for 100 iterations, and obtain the reshaped sets, A_fin and b_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = -0.01\n",
    "test_p = 0.1\n",
    "# split the data into train and test\n",
    "train, _ = train_test_split(data, test_size=int(\n",
    "    data.shape[0]*test_p), random_state=5)\n",
    "\n",
    "# formulate the mean-variance set using the training data\n",
    "init = sc.linalg.sqrtm(sc.linalg.inv(np.cov(train.T)))\n",
    "init_bval = -init@np.mean(train, axis=0)\n",
    "\n",
    "# generating a random init\n",
    "# np.random.seed(15)\n",
    "# initn = np.random.rand(n, n) + 0.1*init + 0.5*np.eye(n)\n",
    "# init_bvaln = -initn@(np.mean(train, axis=0) - 0.3*np.ones(n))\n",
    "\n",
    "result = prob.train(lr=0.01, num_iter=100, momentum=0.8,\n",
    "                            optimizer=\"SGD\",\n",
    "                            seed=5, init_A=init, init_b=init_bval,\n",
    "                            init_lam=0.5, init_mu=0.01,\n",
    "                            mu_multiplier=1.001, init_alpha=0., test_percentage=test_p, kappa=kappa,\n",
    "                            n_jobs=8, random_init=True, num_random_init=5, parallel = True, position=False)\n",
    "A_fin = result.A\n",
    "b_fin = result.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now show the pareto curve of the out-of-sample objective value vs. the probability of constraint violation for the mean-variance and reshpaed sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = np.linspace(0.0001, 4, 200)\n",
    "\n",
    "# Grid search epsilon\n",
    "result4 = prob.grid(epslst=eps_list, init_A=init,\n",
    "                    init_b=init_bval, seed=8,\n",
    "                    init_alpha=0., test_percentage=test_p, quantiles = (0.4, 0.6))\n",
    "dfgrid = result4.df\n",
    "\n",
    "result5 = prob.grid(epslst=eps_list, init_A=A_fin, init_b=b_fin, seed=8,\n",
    "                    init_alpha=0., test_percentage=test_p,quantiles = (0.4,0.6))\n",
    "dfgrid2 = result5.df\n",
    "\n",
    "prob_list = np.array([0.,0.01,0.05,0.1])\n",
    "inds_standard = []\n",
    "inds_reshaped = []\n",
    "for i in prob_list:\n",
    "    inds_standard.append(np.absolute(np.mean(np.vstack(dfgrid['Probability_violations_test']),axis = 1)-i).argmin())\n",
    "    inds_reshaped.append(np.absolute(np.mean(np.vstack(dfgrid2['Probability_violations_test']),axis = 1)-i).argmin())\n",
    "st_eps = eps_list[inds_standard[0]]\n",
    "re_eps = eps_list[inds_reshaped[0]]\n",
    "beg1, end1 = 0, 2000\n",
    "beg2, end2 = 0, 2000\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(np.mean(np.vstack(dfgrid['Probability_violations_test']), axis=1)[beg1:end1], np.mean(np.vstack(\n",
    "    dfgrid['Test_val']), axis=1)[beg1:end1], color=\"tab:blue\", label=r\"Mean-Var set\", marker=\"v\", zorder=0)\n",
    "plt.fill(np.append(dfgrid['Probability_violations_test'][beg1:end1],dfgrid['Probability_violations_test'][beg1:end1][::-1]), np.append(dfgrid['Lower_test'][beg1:end1],dfgrid['Upper_test'][beg1:end1][::-1]), color=\"tab:blue\", alpha=0.2)\n",
    "for ind in range(4):\n",
    "    plt.scatter(np.mean(np.vstack(dfgrid['Probability_violations_test']), axis=1)[inds_standard[ind]], np.mean(np.vstack(\n",
    "        dfgrid['Test_val']), axis=1)[inds_standard[ind]], color=\"tab:green\", s=50, marker=\"v\", zorder=10)\n",
    "plt.plot(np.mean(np.vstack(dfgrid2['Probability_violations_test']), axis=1)[beg2:end2], np.mean(np.vstack(\n",
    "    dfgrid2['Test_val']), axis=1)[beg2:end2], color=\"tab:orange\", label=\"Reshaped set\", marker=\"^\", zorder=1)\n",
    "plt.fill(np.append(dfgrid2['Probability_violations_test'][beg2:end2],dfgrid2['Probability_violations_test'][beg2:end2][::-1]), np.append(dfgrid2['Lower_test'][beg2:end2],dfgrid2['Upper_test'][beg2:end2][::-1]), color=\"tab:orange\", alpha=0.2)\n",
    "for ind in [0, 2, 1, 3]:\n",
    "    plt.scatter(np.mean(np.vstack(dfgrid2['Probability_violations_test']), axis=1)[inds_reshaped[ind]], np.mean(\n",
    "        np.vstack(dfgrid2['Test_val']), axis=1)[inds_reshaped[ind]], color=\"black\", s=50, marker=\"^\")\n",
    "plt.ylabel(\"Objective value\")\n",
    "plt.xlabel(r\"Probability of constraint violation $(\\hat{\\eta})$\")\n",
    "minv, maxv = (-0.25,-0.1)\n",
    "minv, maxv = (-0.5,-0.2)\n",
    "plt.vlines(ymin=minv, ymax=maxv, x=prob_list[0], linestyles=\":\",\n",
    "           color=\"tab:red\", label=\"Reference $\\hat{\\eta}$\")\n",
    "for i in prob_list[1:]:\n",
    "    plt.vlines(ymin=minv, ymax=maxv, x=i, linestyles=\":\", color=\"tab:red\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# plt.savefig(\"portlinear_objective_vs_violations.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3ed6dde042e78d86e091991aef4e6276872e8fbcb7e1edcb6e9eacd7157f213"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
