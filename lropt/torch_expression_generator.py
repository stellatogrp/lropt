from functools import partial
from typing import Any, Dict

import cvxpy as cp
import numpy as np
import torch
from cvxpy.expressions.expression import Expression
from cvxpy.expressions.leaf import Leaf
from cvxtorch import TorchExpression, VariablesDict

from lropt.train.batch import batchify
from lropt.train.parameter import ContextParameter
from lropt.uncertain_parameter import UncertainParameter


def gen_torch_exp(expr: Expression, vars_params: Dict[int, Any], batch_flag: bool = True):
    """
    This function generates a torch expression to be used by RobustProblem from an expression
    and a vars_dict generated by any cvxpy expression. Also returns a variable indicating
    if this toch_exp has uncertain parameters or not.
    """

    def gen_args_inds_to_pass(vars_params, vars_dict):
        """
        This is a helper function that generates a dictionary from a variable/parameter index
        in vars_params (a dictionary that contains all the problem's variables/parameters)
        to vars_dict (a dictionary that contains all the expression's variables/parameters)
        """
        args_inds_to_pass = dict()
        for global_ind, var_param in vars_params.items():
            if var_param not in vars_dict.vars_dict.keys():
                continue
            args_inds_to_pass[global_ind] = vars_dict.vars_dict[var_param]
        return args_inds_to_pass

    def wrapped_function(torch_exp, args_inds_to_pass: dict[int, int], batch_flag: bool,
                         vars_dict: VariablesDict, *args):
        """
        This is the function that wraps the torch expression.

        Args:
            torch_exp:
                A function (partial)
            args_inds_to_pass:
                A dictionary from index in *args to the args that will be passed.
                Note that len(args) > len(args_inds_to_pass) is possible.
            batch_flag (bool):
                Batch mode on/off.
            vars_dict (VariablesDict):
                The VariablesDict of the torch expression. It is not used by this function,
                but it is passed in case it will need to be accessed by another function in
                the future.
            *args
                The arguments of torch_exp
        """

        def _safe_increase_axis(expr: Expression, arg_to_orig_axis: dict) -> None:
            """
            This is an internal function that increases expr.axis by 1 if it is not negative.
            It is needed because we add a new dimension that is reserved for batching, and when
            CVXPY atoms are created, they are unaware of that.
            The increase happens only if batch mode is recognized.
            """

            #Recursively increase the axis of the expression
            for arg in expr.args:
                if isinstance(arg, Leaf):
                    arg_to_orig_axis[arg] = False
                    continue
                _safe_increase_axis(arg, arg_to_orig_axis)

            if not hasattr(expr, "axis"):
                arg_to_orig_axis[expr] = False
                return
            original_axis = expr.axis
            arg_to_orig_axis[expr] = original_axis

            #If axis=None is equivalent to 0. This is needed to make sure numeric functions
            #do not flatten the inputs.
            if expr.axis is None:
                expr.axis = 0

            if expr.axis>=0:
                expr.axis += 1

        def _restore_original_axis(expr: Expression, arg_to_orig_axis: dict) -> None:
            """
            This is an internal function restores the original axis to the expression and all
            of its sub expressions.
            """
            for arg in expr.args:
                #Recursively restore original axis of the subexpressions
                _restore_original_axis(arg, arg_to_orig_axis)
                #Restore the original axis of this expression
            original_axis = arg_to_orig_axis[expr]
            if original_axis is not False:
                expr.axis = original_axis

        args_to_pass = [None]*len(args_inds_to_pass)
        for key, value in args_inds_to_pass.items():
            args_to_pass[value] = args[key]

        #To make sure batched inputs are processed correctly, we need to update expr.axis
        #(if applicable). It is important to revert it back to the original value when done,
        #hence we save original_axis.
        expr = torch_exp.args[1] #torch_exp.args[1] is the expression
        if batch_flag:
            arg_to_orig_axis = {} #Expression (arg) -> original axis dictionary
            _safe_increase_axis(expr, arg_to_orig_axis)
        res = torch_exp(*args_to_pass)
        #Revert to the original axis if applicable. Note: None is a valid axis (unlike False).
        if batch_flag:
            _restore_original_axis(expr, arg_to_orig_axis)
        return res

    # vars_dict contains a dictionary from variable/param -> index in *args (for the expression)
    # THIS BATCHIFY IS IMPORTANT, BOTH OF THEM ARE NEEDED!
    if batch_flag:
        expr = batchify(expr)
    cvxtorch_exp = TorchExpression(expr)
    torch_exp = cvxtorch_exp.torch_expression
    vars_dict = cvxtorch_exp.variables_dictionary
    # Need to rebatchify because cvxtorch may introduce new unbatched add atoms
    if batch_flag:
        torch_exp = batchify(torch_exp)

    # Create a dictionary from index -> variable/param (for the problem)
    args_inds_to_pass = gen_args_inds_to_pass(vars_params, vars_dict)

    return partial(wrapped_function, torch_exp, args_inds_to_pass, batch_flag, vars_dict)


def generate_torch_expressions(problem, eval_exp: Expression | None = None):
    """
    This function generates torch expressions for the canonicalized objective and constraints.

    Args:
        problem: The RobustProblem instance
        eval_exp: Optional expression to evaluate

    Returns:
        None - modifies the problem in place
    """
    problem.f = gen_torch_exp(problem.objective.expr, problem.vars_params)
    problem.g = []
    problem.g_shapes = []
    problem.num_g_total = 0
    problem.constraint_checkers = []

    # For each max_id, select all the constraints with this max_id:
    # Each of these constraints is NonPos, so constraint.args[0] is an expression.
    # Create an object (list) that has all constraint.args[0] from all these constraints.
    # new_constraint = cp.NonPos(cp.Maximum(all of these expressions))
    # new_constraint is fed to gen_torch_exp, but I shouldn't modify problem.constraints
    for max_id in problem.constraints_by_type.keys():
        if max_id == problem.CERTAIN_ID:  # Nothing to do with certain constraints
            continue
        elif max_id == problem.UNCERTAIN_NO_MAX_ID:
            constraints = problem.constraints_by_type[max_id]
        else:
            # Create a constraint from all the constraints of this max_id
            args = [constraint.args[0] for constraint in problem.constraints_by_type[max_id]]
            constraints = [cp.NonNeg(-cp.maximum(*args))]
        for constraint in constraints:  # NOT problem.constraints: these are the new constraints
            g = gen_torch_exp(constraint, problem.vars_params)
            problem.g.append(g)  # Always has uncertainty, no need to check
            if len(constraint.shape) >= 1:
                problem.g_shapes.append(constraint.shape[0])
                problem.num_g_total += constraint.shape[0]
            else:
                problem.g_shapes.append(1)
                problem.num_g_total += 1

    if problem.eval_exp is None:
        problem.eval_exp = problem.objective.expr
    problem.eval = gen_torch_exp(problem.eval_exp, problem.vars_params, batch_flag=False)

    # Generate h functions from g functions
    generate_h_functions(problem)


def generate_h_functions(problem):
    """
    Generates h functions from g functions for the problem.

    Args:
        problem: The RobustProblem instance

    Returns:
        None - modifies the problem in place
    """
    import torch

    import lropt.train.settings as settings

    h_funcs = []
    for g in problem.g:
        def hg(*args, **kwargs):
            return (torch.maximum(g(*args) - kwargs["alpha"], torch.tensor(0.0,
                            dtype=settings.DTYPE, requires_grad=problem.train_flag))/kwargs["eta"])

        h_funcs.append(hg)

    problem.h = h_funcs
    problem.num_g = len(h_funcs)


def get_eval_batch_size(problem) -> int:
    """
    This function returns the batch size based on all ContextParameters and UncertainParameters.
    If there are no ContextParameters or UncertainParameters, returns 1.

    Args:
        problem: The RobustProblem instance

    Returns:
        int: The batch size

    Raises:
        ValueError if inconsistent batch sizes are found.
        AttributeError if eval_data is missing from a ContextParameter or an UncertainParameter.
    """
    def _get_curr_batch_size(var_param) -> int:
        """
        This function returns the batch size of the current var_param.
        Raises AttributeError if eval_data does not exist.
        """
        if not hasattr(var_param, "eval_data"):
            raise AttributeError(f"The parameter {var_param} has no eval_data.")
        eval_data = var_param.eval_data
        if isinstance(eval_data, (float, int)):
            return 1
        if isinstance(eval_data, (torch.Tensor, np.ndarray)):
            return eval_data.shape[0]
        return len(eval_data)

    batch_size = None
    for var_param in problem.problem_canon.vars_params.values():
        if not isinstance(var_param, (ContextParameter, UncertainParameter)):
            continue
        if not batch_size:
            batch_size = _get_curr_batch_size(var_param=var_param)
        else:
            if batch_size != _get_curr_batch_size(var_param=var_param):
                raise ValueError("Inconsistent batch sizes.")
    if not batch_size:
        batch_size = 1
    return batch_size


def get_eval_data(problem, tch_exp, batch_num: int) -> list[torch.Tensor]:
    """
    This function generates a list of inputs (as torch.expressions) from eval_data of all the
    Contextual Parameters and Uncertain Parameters, as well as value from CVXPY variables
    and Parameters.

    Args:
        problem: The RobustProblem instance
        tch_exp (partial):
            A torch expression, as the output of gen_torch_exp
        batch (int):
            Batch number.

    Returns:
        A list of inputs (as torch.Tensor) for the torch expression.
    """
    from lropt.train.parameter import ContextParameter
    from lropt.uncertain_parameter import UncertainParameter

    def _get_data(var_param, batch_num: int) -> torch.Tensor:
        """
        This helper function returns eval_data for LROPT types, or value for CVXPY types.
        """
        # Get the data from the correct field.
        if isinstance(var_param, (ContextParameter, UncertainParameter)):
            value = var_param.eval_data[batch_num]
        else:
            value = var_param.value

        # Transform into a torch.Tensor
        if isinstance(value, (float, int)):
            value = [value]
        return torch.Tensor(value)

    # Get the vars_dict
    vars_dict = tch_exp.args[3]
    assert isinstance(vars_dict, VariablesDict)

    # Populate eval_data
    eval_data = [None] * len(vars_dict)
    for var_param in problem.vars_params.values():
        if var_param not in vars_dict.vars_dict:
            continue
        # Get data
        data = _get_data(var_param=var_param, batch_num=batch_num)

        # Set in the correct position
        ind = vars_dict.vars_dict[var_param]
        eval_data[ind] = data

    return eval_data
